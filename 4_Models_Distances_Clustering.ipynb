{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models based on distances: Clustering\n",
    "Remembering, clustering consists of group samples based on the features.\n",
    "<img src=\"images/4_clustering.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering\n",
    "Unsupervised learning: Clustering\n",
    "Variable type: all\n",
    "\n",
    "Hierarchical clustering works in an iterative way. The algorithm is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Input: samples\n",
    "    Begin\n",
    "        Each sample is a cluster\n",
    "        Repeat until there is only one cluster\n",
    "        Join the nearest two clusters\n",
    "    End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/4_hierarchical_clustering.png\">\n",
    "\n",
    "We can represent the clustering process with a __dendrogram__ that is a binary tree where the length of the branch represents the distance where the samples were joined. It can be used to analyze the number of clusters. By pruning the tree, the clusters can be found. [See examples](https://www.google.com/search?q=hierarchical+clustering&safe=strict&rlz=1C1SQJL_enMX896MX896&sxsrf=ALeKk02baKxOqwwmU5bdgI_nNPd5XKnDYg:1615495969868&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjV0627j6nvAhXihK0KHa18CoQQ_AUoAXoECAkQAw&biw=1517&bih=631).\n",
    "\n",
    "__Disadvantage__: It is very complex because the distances among all clusters (at the beginning of all samples) need to be calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Means\n",
    "Unsupervised learning: Clustering\n",
    "Variable type: all\n",
    "\n",
    "k-means finds k groups in the unlabeled data. The algorithm is:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Input: samples and k (the number of clusters)\n",
    "    Begin\n",
    "        Randomly select k prototypes\n",
    "        Repeat until the prototypes donâ€™t move\n",
    "            Assign the samples to the nearest prototype\n",
    "            Update the prototypes as the centroid of the samples\n",
    "    End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/4_kmeans.png\">\n",
    "\n",
    "__Disadvantage__: You need to set the number of groups __k__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Models (GMM)\n",
    "Unsupervised learning: Clustering\n",
    "Variable type: all\n",
    "\n",
    "In the next figure we can observe the Normal distribution, represented as a Gaussian function.\n",
    "<img src=\"images/4_gmm_gaussian.png\">\n",
    "\n",
    "The probability density function of a normal distribution centered in $u$ with covariance $\\sigma^2$ is:\n",
    "$ P(x|u,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-u)^2}{2\\sigma^2}} $\n",
    "\n",
    "The probability density function of a multivariate normal distribution centered in $\\mu \\in \\mathbb{R}^d$, with covariance matrix $\\sum \\in \\mathbb{R}^{dxd}$ is:\n",
    "$ P(X|\\mu,\\sum)= \\frac{1}{\\sqrt{ (2\\pi)^d |\\sum|}} e^{-\\frac{1}{2} (X-\\mu)^T \\sum^{-1}(X-\\mu)} $\n",
    "\n",
    "A GMM can be used for finding k groups in unlabeled data. The main difference with k-means is that it searches groups that belong to multivariate normal distributions instead of spheres. Its algorithm is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Input: X (training set nSamples x nFeatures) and k (number of Gaussians)\n",
    "    Randomly calculate K prototypes (centroids and covariance matrices)\n",
    "    Repeat until convergence\n",
    "        Assign the samples to the Gaussian with more likelihood\n",
    "        Calculate the parameters of the K Gaussians based on the samples assigned to them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
